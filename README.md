# 新聞爬蟲系統 - 優化版本

## 📋 優化內容摘要

### 1. **程式架構優化**
- ✅ 使用 **物件導向設計**（OOP），提升代碼可維護性
- ✅ 採用 **數據類別** (dataclass) 管理數據結構
- ✅ **關注點分離**：將驗證、爬取、存儲等功能模組化
- ✅ 增加 **ScraperManager** 統一管理所有爬蟲

### 2. **錯誤處理與穩定性**
- ✅ **重試機制**：請求失敗自動重試（最多 3 次）
- ✅ **指數退避**：重試時延遲遞增避免過載
- ✅ **Session 管理**：使用 requests.Session 提升效能
- ✅ **完善的異常處理**：捕獲所有可能的錯誤情況
- ✅ **日誌雙輸出**：同時輸出到控制台和日誌文件

### 3. **代碼品質提升**
- ✅ **URL 標準化**：使用 urljoin 正確處理相對路徑
- ✅ **URL 驗證**：檢查 URL 有效性避免無效連結
- ✅ **類型提示**：完整的 type hints 提升可讀性
- ✅ **文檔字串**：為所有函數添加詳細說明
- ✅ **常量管理**：集中定義便於調整

### 4. **功能增強**
- ✅ **執行時間統計**：顯示爬取耗時
- ✅ **數據豐富化**：記錄抓取時間、來源統計等
- ✅ **摘要報告**：生成易讀的文本摘要
- ✅ **目錄自動創建**：確保輸出目錄存在
- ✅ **配置文件支援**：方便自定義設定（見 config.json）

### 5. **效能優化**
- ✅ Session 複用減少連接開銷
- ✅ 使用 Set 追蹤已見 URL，O(1) 查詢
- ✅ 提前終止：達到數量上限立即停止
- ✅ 並行執行保持高效

---

## 🚀 使用方式

### 基本使用
```bash
python news_scraper_optimized.py
```

### 輸出文件
執行後會生成以下文件：
- `news.json` - 完整的新聞數據（JSON 格式）
- `news_summary.txt` - 易讀的摘要報告
- `scraper.log` - 詳細的執行日誌

---

## 📁 文件結構

```
news_scraper_optimized.py  # 主程式
config.json               # 配置文件（可選）
news.json                 # 輸出：新聞數據
news_summary.txt          # 輸出：文本摘要
scraper.log              # 輸出：執行日誌
```

---

## 🔧 自定義配置

### 修改爬取參數
在程式中找到以下常量並修改：

```python
MAX_NEWS_PER_SOURCE = 15  # 每個來源最多抓取文章數
REQUEST_TIMEOUT = 10      # 請求超時時間（秒）
MAX_WORKERS = 3           # 並行線程數
MAX_RETRIES = 3           # 最大重試次數
```

### 新增網站
在 `SCRAPERS_CONFIG` 中添加新配置：

```python
'網站代號': ScraperConfig(
    url='網站網址',
    source='來源名稱',
    category='分類',
    min_title_length=最小標題長度,
    domain_check='域名檢查關鍵字',
    url_pattern='URL 必須包含的模式',
    exclude_titles=['要排除的標題關鍵字'],
    base_url='基礎 URL（處理相對路徑）'
)
```

---

## 📊 輸出範例

### JSON 格式
```json
{
  "update_time": "2025-02-07 14:30:15",
  "total_count": 45,
  "sources": ["Unwire.hk", "New MobileLife", "HolidaySmart"],
  "categories": ["科技", "旅遊"],
  "news": [
    {
      "title": "文章標題",
      "link": "https://...",
      "source": "Unwire.hk",
      "category": "科技",
      "scraped_at": "2025-02-07 14:30:15"
    }
  ]
}
```

### 文本摘要格式
```
新聞爬取摘要
============================================================
更新時間: 2025-02-07 14:30:15
總文章數: 45

Unwire.hk (15 篇)
------------------------------------------------------------
1. 文章標題
   https://...
```

---

## 🔍 主要改進對比

| 項目 | 原始版本 | 優化版本 |
|------|---------|---------|
| 架構 | 函數式 | 物件導向 |
| 錯誤處理 | 基本 try-catch | 重試機制 + 完善日誌 |
| URL 處理 | 簡單拼接 | urljoin 標準化 |
| 數據結構 | 字典 | dataclass |
| 日誌 | 僅控制台 | 控制台 + 文件 |
| 輸出 | JSON | JSON + 文本摘要 |
| 配置 | 硬編碼 | 集中管理 |
| 代碼行數 | ~200 | ~450（含完整文檔） |

---

## ⚠️ 注意事項

1. **遵守網站規範**：請確保遵守目標網站的 robots.txt 和使用條款
2. **請求頻率**：避免過於頻繁的請求造成伺服器負擔
3. **網站結構變更**：若網站改版，可能需要調整選擇器
4. **依賴套件**：需要安裝 `requests` 和 `beautifulsoup4`

```bash
pip install requests beautifulsoup4
```

---

## 📝 開發建議

### 進一步優化方向
1. 使用 `aiohttp` 實現真正的非同步爬取
2. 加入 Redis/SQLite 數據庫儲存
3. 實現增量更新（只抓取新文章）
4. 添加郵件通知功能
5. 建立 Web API 提供數據
6. 實現圖片下載功能
7. 加入 NLP 分析（摘要、分類）

### 監控指標
- 成功率：成功抓取的網站比例
- 平均響應時間
- 錯誤類型分布
- 重複 URL 數量

---

## 📄 授權
此代碼僅供學習和個人使用。商業使用請確保遵守相關法律法規。

---

## 🆘 疑難排解

### Q: 無法抓取某個網站
A: 檢查網站是否可訪問、是否有防爬機制、選擇器是否正確

### Q: 抓取速度慢
A: 增加 `MAX_WORKERS` 數量，但不要過高避免被封鎖

### Q: 記憶體占用高
A: 減少 `MAX_NEWS_PER_SOURCE` 或分批處理

### Q: 編碼錯誤
A: 確保所有文件使用 UTF-8 編碼
